TITLE: Demo - Cubic nonlinear Klein-Gordon equation 
AUTHOR: Mikael Mortensen {copyright|CC BY} Email:mikaem@math.uio.no at Department of Mathematics, University of Oslo.
DATE: today

__Summary.__
To come

TOC: on


======= The nonlinear Klein-Gordon equation =======
% if FORMAT in ("latex", "pdflatex"):

FIGURE: [figs/Klein_Gordon_32_real_8000.png] The solution $u$ from Eq. (ref{eq:kg}), at $t=40$, in a slice through the center of the domain, computed with the code described in this demo. label{mov:kleingordon}

% else:

MOVIE: [movies/KleinGordon.gif] Movie showing the evolution of the solution $u$ from Eq. (ref{eq:kg}), in a slice through the center of the domain, computed with the code described in this demo. label{mov:kleingordon}

% endif

===== Model equation =====

The cubic nonlinear Klein-Gordon equation is a wave equation important for many
scientific applications such as solid state physics, nonlinear optics and
quantum field theory cite{abdul08}. The equation is given as

!bt
\begin{equation}
\frac{\partial^2 u}{\partial t^2} = \nabla^2 u - \gamma(u - u|u|^2) \quad
\text{for} \, u \in
\Omega, label{eq:kg}
\end{equation}
!et
with initial conditions
!bt
\begin{equation}
u(\boldsymbol{x}, t=0) = u^0 \quad \text{and} \quad \frac{\partial u(\boldsymbol{x},
t=0)}{\partial t} = u_t^0. label{eq:init}
\end{equation}
!et

The parameter $\gamma=\pm 1$ determines whether the equations are focusing
($1$) or defocusing ($-1$) (in the movie we have used $\gamma=1$). The domain $\Omega=[-2\pi, 2\pi]^3$ is triply
periodic and Initial conditions will here be set as

!bt
\begin{align}
u^0 &= 0.1 \exp \left( -\boldsymbol{x} \cdot \boldsymbol{x} \right), \\
u_t^0 &= 0.
\end{align}
!et

with $\boldsymbol{x} = (x, y, z)$. We will solve these equations using a mixed formulation and a spetral Galerkin
method. The mixed formulation reads

!bt
\begin{align}
\frac{\partial f}{\partial t} &= \nabla^2 u - \gamma (u - u|u|^2), label{eq:df}\\
\frac{\partial u}{\partial t} &= f. label{eq:du}
\end{align}
!et

The energy of the solution can be computed as
!bt
E(u) = \int_{\Omega} \left( \frac{1}{2} f^2 + \frac{1}{2}|\nabla u|^2 +
\gamma(\frac{1}{2}u^2 - \frac{1}{4}u^4) \right)
!et
and it is crucial that this energy remains constant in time.

% if FORMAT in ("latex", "pdflatex"):

The Figure (ref{mov:kleingordon}) is showing the solution $u$, computed with the
code shown in the bottom of Sec. ref{sec:solver}. A movie can be found "here":
"https://github.com/spectralDNS/spectralutilities/blob/master/movies/KleinGordon.gif".

% else:

The movie (ref{mov:kleingordon}) is showing the solution $u$, computed with the
code shown in the bottom of Sec. ref{sec:solver}.

%endif

===== Spectral Galerkin formulation =====
The PDEs in (ref{eq:df}) and (ref{eq:du}) can be solved with many different
numerical methods. We will here use the "shenfun":
"https://github.com/spectralDNS/shenfun" software and this software makes use of
the spectral Galerkin method. Being a Galerkin method, we need to reshape the
governing equations into proper variational forms, and this is done by
multiplying  (ref{eq:df}) and (ref{eq:du}) with the complex conjugate of proper
test functions and then integrating
over the domain. To this end we use testfunction $g\in H^1(\Omega)$ with
Eq. (ref{eq:df})  and  $v \in
H^1(\Omega)$ with Eq. (ref{eq:du}), where $H^1(\Omega)$ is the Sobolev space, and we obtain

!bt
\begin{align}
\frac{\partial}{\partial t} \int_{\Omega} f\, \overline{g} \,dx &= \int_{\Omega}
\left(\nabla^2 u \, \overline{g}
- \gamma( u\, - u|u|^2) \, \overline{g} \right) \,dx, label{eq:df_var} \\
\frac{\partial }{\partial t} \int_{\Omega} u\, \overline{v} \, dx &=
\int_{\Omega} f\, \overline{v} \, dx. label{eq:du_var}
\end{align}
!et
Note that the overline is used to indicate a complex conjugate. The functions $f$ and $u$ are now
to be considered as trial functions, and the integrals over the
domain are often referred to as inner products. With inner product notation

!bt
\[
\left(u, v\right) = \int_{\Omega} u \, \overline{v} \, dx.
\]
!et
and an integration by parts on the Laplacian, the spatially discretized variational problem can be
formulated as: Find $(u, f) \in H^1(\Omega) \times H^1(\Omega)$ such that
!bt
\begin{align}
\frac{\partial}{\partial t} (f, g) &= -(\nabla u, \nabla g)
-\gamma \left( u - u|u|^2, g \right), label{eq:df_var2} \\
\frac{\partial }{\partial t} (u, v) &= (f, v) \quad \forall \, (v,g) \in
H^1(\Omega) \times H^1(\Omega). label{eq:du_var2}
\end{align}
!et 

The time discretization is
still left open. There are numerous different approaches that one could take for
discretizing in time, and the first two terms on the right hand side of
(ref{eq:df_var2}) can easily be treated implicitly as well as explicitly. However,
the approach we will follow in Sec. (ref{sec:rk}) is a fully explicit 4th order "Runge-Kutta":
"https://en.wikipedia.org/wiki/Runge-Kutta_methods" method.

===== Discretization =====
To find a numerical solution we need to discretize the continuous problem
(ref{eq:df_var2}) and (ref{eq:du_var2}) in space as well as time. Since the
problem is triply periodic, Fourier exponentials are normally the best choice
for trial and test functions, and as such we use basis functions 

!bt
\begin{equation}
\phi_l(x) = e^{\imath \underline{l} x}, \quad -\infty < l < \infty,
\end{equation}
!et
where $l$ is the wavenumber, and
$\underline{l}=\frac{2\pi}{L}l$ is the scaled wavenumber, scaled with domain
length $L$ (here $4\pi$). Since we want to solve these equations on a computer, we need to choose
a finite number of test functions. A basis $V^N$ can be defined as

!bt
\begin{equation}
V^N(x) = \text{span} \{\phi_l(x)\}_{l\in \boldsymbol{l}}, label{eq:Vn}
\end{equation}
!et
where $N$ is chosen as an even positive integer and $\boldsymbol{l} = (-N/2,
-N/2+1, \ldots, N/2-1)$. And now, since $\Omega$ is a
three-dimensional domain, we can create Cartesian products of such bases to get,
e.g., for three dimensions

!bt
\begin{equation}
W^{\boldsymbol{N}}(x, y, z) = V^N(x) \times V^N(y) \times V^N(z), label{eq:Wn}
\end{equation}
!et
where $\boldsymbol{N} = (N, N, N)$. Obviously, it is not necessary to use the
same number ($N$) of basis functions for each direction, but it is done here
for simplicity. A 3D tensor product basis function is now defined as

!bt
\begin{equation}
\Phi_{l,m,n}(x,y,z) = e^{\imath \underline{l} x} e^{\imath \underline{m} y}
e^{\imath \underline{n} z} = e^{\imath
(\underline{l}x + \underline{m}y + \underline{n}z)}
\end{equation}
!et
and we look for solutions of the form

!bt
\begin{equation}
u(x, y, z) = \sum_{n=-N/2}^{N/2-1}\sum_{m=-N/2}^{N/2-1}\sum_{l=-N/2}^{N/2-1}
\hat{u}_{l,m,n} \Phi_{l,m,n}(x,y,z). 
\end{equation}
!et

The expansion coefficients $\hat{u}_{l,m,n}$ can be related directly to the solution $u(x,
y, z)$ using Fast Fourier Transforms (FFTs) if we are satisfied with obtaining
the solution in quadrature points corresponding to

!bt
\begin{align}
 x_i &= \frac{4 \pi i}{N}-2\pi, \quad \forall \, i \in \boldsymbol{i},
\text{where}\, \boldsymbol{i}=(0,1,\ldots,N-1), \\
 y_j &= \frac{4 \pi j}{N}-2\pi, \quad \forall \, j \in \boldsymbol{j},
\text{where}\, \boldsymbol{j}=(0,1,\ldots,N-1) \\
 z_k &= \frac{4 \pi k}{N}-2\pi, \quad \forall \, k \in \boldsymbol{k},
\text{where}\, \boldsymbol{k}=(0,1,\ldots,N-1) \\
\end{align}
!et
Note that these points are different from the standard (like $2\pi j/N$) since
the domain
is set to $[-2\pi, 2\pi]^3$ and not the more common $[0, 2\pi]^3$. We have

!bt
\begin{equation}
u(x_i, y_j, z_k) =
N^3
\mathcal{F}_k^{-1}\left(\mathcal{F}_j^{-1}\left(\mathcal{F}_i^{-1}\left(\hat{u}\right)\right)\right),
\, \forall\, (i,j,k)\in\boldsymbol{i} \times \boldsymbol{j} \times \boldsymbol{k}
\end{equation}
!et
where $\mathcal{F}_i^{-1}$ is the inverse Fourier transform along the direction
of index $i$, for
all $(j, k) \in \boldsymbol{j} \times \boldsymbol{k}$. Note that the three
inverse FFTs are performed sequentially, one direction at the time, and that the factor $N^3$ is due to
the definition used for the inverse Fourier transform, which is the one used by Numpy:

!bt
\begin{equation}
u(x_j) = \frac{1}{N}\sum_{l=-N/2}^{N/2-1} \hat{u}_l e^{\imath \underline{l}
x_j}, \quad \,\, \forall \, j \in \, \boldsymbol{j}.
\end{equation}
!et

The inner products used in Eqs. (ref{eq:df_var2}), (ref{eq:du_var2}) may be
computed using forward FFTs:

!bt
\begin{equation}
\left(u, \Phi_{l,m,n}\right) =
\left(\frac{2\pi}{N}\right)^3
\mathcal{F}_l\left(\mathcal{F}_m\left(\mathcal{F}_n\left({u}\right)\right)\right)
\quad \forall (l,m,n) \in \boldsymbol{l} \times \boldsymbol{m} \times
\boldsymbol{n},
\end{equation}
!et

whereas a complete transform requires
!bt
\begin{equation}
\hat{u}_{l,m,n} =
\left(\frac{1}{N}\right)^3
\mathcal{F}_l\left(\mathcal{F}_m\left(\mathcal{F}_n\left(u\right)\right)\right)
\quad \forall (l,m,n) \in \boldsymbol{l} \times \boldsymbol{m} \times
\boldsymbol{n}.
\end{equation}
!et

From this we see that the variational forms (ref{eq:df_var2}) and (ref{eq:du_var2})
may be written in terms of the Fourier transformed quantities $\hat{u}$ and
$\hat{f}$. Expanding the exact derivatives of the nabla operator, the equations
to be solved can be found directly as

!bt
\begin{align}
\frac{\partial \hat{f}}{\partial t}  &=
\left(-(\underline{l}^2+\underline{m}^2+\underline{n}^2+\gamma)\hat{u} + \gamma \widehat{u|u|^2}\right), label{eq:df_var3} \\
\frac{\partial \hat{u}}{\partial t} &= \hat{f}. label{eq:du_var3}
\end{align}
!et

There is more than one way to arrive at these equations. Taking the 3D Fourier
transform of both equations  (ref{eq:df}) and (ref{eq:du}) is one obvious way.
With the Python module "shenfun": "https://github.com/spectralDNS/shenfun", one can work with the
inner products as seen in (ref{eq:df_var2}) and (ref{eq:du_var2}), or the Fourier
transforms directly.  In short, `shenfun` contains all the tools required to work with
the spectral Galerkin method, and we will now see how `shenfun` can be used to solve
the Klein-Gordon equation. 

#We simplify notation by writing three-dimensional inner products as
#!bt
#\begin{align}
# (u, v) &= \mathcal{S}(u), \\
#        &= \left(\frac{2\pi}{N}\right)^3 \mathcal{F}(u)
#\end{align}
#!et
#and three-dimensional transforms as
#!bt
#\begin{align}
#\hat{u} &= \mathcal{T}(u), \\
#        &= \left(\frac{1}{N}\right)^3 \mathcal{F}(u)
#\end{align}
#!et
#with inverse $u = \mathcal{T}^{-1}(\hat{u})$.


======= Implementation =======

To solve the Klein-Gordon equations we need to make use of the Fourier bases in
`shenfun`, and these base are found in submodule `shenfun.fourier.bases`.
The triply periodic domain allows for Fourier in all three directions, and we
can as such
create one instance of the base class "C2CBasis":
"https://github.com/spectralDNS/shenfun/blob/49170fe03ee5b3aa989d7c2387f825707d17c62e/shenfun/fourier/bases.py#L195"
for each direction (`C2C` here meaning complex to complex). However, since the initial data are real, we
can take advantage of Hermitian symmetries and thus make use of the "R2CBasis":
"https://github.com/spectralDNS/shenfun/blob/49170fe03ee5b3aa989d7c2387f825707d17c62e/shenfun/fourier/bases.py#L94"
(real to complex) class for one (but only one) of the directions. We can only make use of the
`R2CBasis` for the direction that we choose to transform first with the forward
FFT, and the reason is obviously that the output from a forward transform of
real data is now complex. We may start implementing the solver as follows 

!bc pycod
from shenfun import *
from mpi4py import MPI
import numpy as np

# Set size of discretization
N = (32, 32, 32)

# Create bases
K0 = fourier.bases.C2CBasis(N[0], domain=(-2*np.pi, 2*np.pi))
K1 = fourier.bases.C2CBasis(N[1], domain=(-2*np.pi, 2*np.pi))
K2 = fourier.bases.R2CBasis(N[2], domain=(-2*np.pi, 2*np.pi))
!ec 

We now have three instances `K0`, `K1` and `K2`, corresponding to the basis
(ref{eq:Vn}), that each can be used to solve
one-dimensional problems. However, we want to solve a 3D problem, and for this
we need a tensor product basis, like (ref{eq:Wn}), created as a Cartesian product of these three
bases

!bc pycod
# Create communicator
comm = MPI.COMM_WORLD

T = TensorProductSpace(comm, (K0, K1, K2), **{'planner_effort': 
                                              'FFTW_MEASURE'})
!ec

Here the `planner_effort`, which is a flag used by "FFTW":
"http://www.fftw.org", is optional. Possibel choices are from the list
(`FFTW_ESTIMATE`, `FFTW_MEASURE`, `FFTW_PATIENT`, `FFTW_EXHAUSTIVE`), and the
flag determines how much effort FFTW puts in looking for an optimal algorithm
for the current platform. Note that it is also possible to use FFTW "wisdom": "http://www.fftw.org/fftw3_doc/Wisdom.html#Wisdom" with
`shenfun`, and as such, for production, one may perform exhaustive planning once
and then simply import the result of that planning later, as wisdom.

The `TensorProductSpace` instance `T` contains pretty much all we need for
computing inner products or fast transforms between real and wavenumber space.
However, since we are going to solve for a mixed system, it is convenient to also use the
`MixedTensorProductSpace` class

!bc pycod
TT = MixedTensorProductSpace([T, T])
!ec

We need containers for the solution as well as intermediate work arrays for,
e.g., the Runge-Kutta method. Arrays are created as

!bc pycod
uf = Array(TT, False) # Solution array in physical space
u, f = uf[:] # Split solution array by creating two views u and f

duf = Array(TT) # Array for right hand sides
du, df = duf[:] # Split into views

uf_hat = Array(TT)  # Solution in spectral space
uf_hat0 = Array(TT) # Work array 1
uf_hat1 = Array(TT) # Work array 2
u_hat, f_hat = uf_hat[:] # Split into views
!ec

The "Array":
"https://github.com/spectralDNS/shenfun/blob/49170fe03ee5b3aa989d7c2387f825707d17c62e/shenfun/forms/arguments.py#L387"
class is a subclass of Numpy's "ndarray":
"https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html",
without much more functionality than constructors that return arrays of the
correct shape according to the basis used in the construction. A different type
of array is returned by the "Function":
"https://github.com/spectralDNS/shenfun/blob/49170fe03ee5b3aa989d7c2387f825707d17c62e/shenfun/forms/arguments.py#L292"
class, that subclasses both Nympy's ndarray as well as an internal
"BasisFunction":
"https://github.com/spectralDNS/shenfun/blob/49170fe03ee5b3aa989d7c2387f825707d17c62e/shenfun/forms/arguments.py#L219"
class. An instance of the `Function` class may be used as a regular array,
but also as an argument in forms. For example, if you want to compute the
partial derivative $\partial u/\partial x$, then this may be achieved by
projection, i.e., find $u_x \in V^N$ such that $(u_x-\partial u/\partial x, v) = 0$,
for $v \in V^N$. This projection may be easily computed in `shenfun` using

!bc pycod
v = Function(T, False, buffer=u)
ux = project(Dx(v, 0, 1), T)
!ec
where `v` now is an instance of the `Function` class and not the `Array`, like
`u`. The following code, on the other hand, will raise an error since you cannot
use the `Array u` in a form, like `Dx(u, 0, 1)`

!bc pycod
project(Dx(u, 0, 1), T)
!ec

Note that `u` and `v` share the same data, and changing one will as such also
change the other. The reason for having two classes is that regular indexing and
slicing is faster on a *smaller* `Array` class that is carrying less additional
information required by forms. 

===== Initialization =====

The solution arrays `uf` and its transform `uf_hat` need to be initialized according to Eq.
(ref{eq:init}). To this end we use "Sympy":
"http://www.sympy.org/en/index.html", which is a Python library for symbolic
mathamatics.

!bc pycod
from sympy import symbols, exp, lambdify

x, y, z = symbols("x,y,z")
ue = 0.1*exp(-(x**2 + y**2 + z**2))
ul = lambdify((x, y, z), ue, 'numpy')
X = T.local_mesh(True)
u[:] = ul(*X)
u_hat = T.forward(u, u_hat)
!ec

Here `X` is a list of the three mesh coordinates `(x, y, z)` local to the
current processor. Each processor has its own part of the computational mesh,
and the distribution is handled during the creation of the `TensorProductSpace`
class instance `T`. There is no need
to do anything about the `f/f_hat` arrays since they are already initialized by default to
zero. Note that calling the `ul` function with the argument `*X` is the same as
calling with `X[0], X[1], X[2]`.


===== Runge-Kutta integrator =====
label{sec:rk}
A fourth order explicit Runge-Kutta integrator requires only a function that
returns the right hand sides of (ref{eq:df_var3}) and (ref{eq:du_var3}). Such a
function can be implemented as

!bc pycod

gamma = 1            # focusing or defocusing (-1)
uh = TrialFunction(T)
vh = TestFunction(T)
k2 = -(inner(grad(vh), grad(uh)).diagonal_array / A + gamma)

def compute_rhs(duf_hat, uf_hat, up, T, w0):
    duf_hat.fill(0)
    u_hat, f_hat = uf_hat[:]             # Create views
    du_hat, df_hat = duf_hat[:]          # Create views
    df_hat[:] = k2*u_hat                 # (1) Linear terms
    up = T.backward(u_hat, up)
    df_hat += T.forward(gamma*up**3, w0) # (2) Nonlinear term
    du_hat[:] = f_hat
    return duf_hat
!ec

The code is fairly self-explanatory. `k2` represents the coefficients in front of
the linear $\hat{u}$ in (ref{eq:df_var3}). The output array is `duf_hat`, and
the input array is `uf_hat`, whereas `up` and `w0` are work arrays. The array
`duf_hat` contains the right hand side of both (ref{eq:df_var3}) and
(ref{eq:du_var3}), where the linear and nonlinear terms are recognized as `(1)` and `(2)`.
The array `uf_hat` contains the solution at initial and intermediate Runge-Kutta steps.

With a function that returns the right hand side in place, the actual integrator
can be implemented as

!bc pycod
t = 0.0
dt = 0.0025
end_time = 500.
tstep = 0
while t < end_time-1e-8:
    t += dt
    tstep += 1
    uf_hat1[:] = uf_hat0[:] = uf_hat
    for rk in range(4):
        duf = compute_rhs(duf, uf_hat, up, T, w0)
        if rk < 3:
            uf_hat[:] = uf_hat0 + b[rk]*dt*duf
        uf_hat1 += a[rk]*dt*duf
    uf_hat[:] = uf_hat1
!ec 

===== Complete solver =====
label{sec:solver}

A complete solver is given below, with intermediate plotting of the solution and
intermediate computation of the total energy. The total energy is unchanged to 8
decimal points at $t=100$.

!bc pycod
from sympy import symbols, exp, lambdify
import numpy as np
import matplotlib.pyplot as plt
from mpi4py import MPI
from time import time
from shenfun.fourier.bases import R2CBasis, C2CBasis
from shenfun import *

comm = MPI.COMM_WORLD
rank = comm.Get_rank()

# Use sympy to set up initial condition
x, y, z = symbols("x,y,z")
ue = 0.1*exp(-(x**2 + y**2 + z**2))
ul = lambdify((x, y, z), ue, 'numpy')

# Size of discretization
N = (32, 32, 32)

 # Focusing (+1) or defocusing (-1)
gamma = 1 

K0 = C2CBasis(N[0], domain=(-2*np.pi, 2*np.pi))
K1 = C2CBasis(N[1], domain=(-2*np.pi, 2*np.pi))
K2 = R2CBasis(N[2], domain=(-2*np.pi, 2*np.pi))
T = TensorProductSpace(comm, (K0, K1, K2), **{'planner_effort': 
                                              'FFTW_MEASURE'})

TT = MixedTensorProductSpace([T, T])

uf = Array(TT, False)
u, f = uf[:]
up = Array(Tp, False)

duf = Array(TT)
du, df = duf[:]

uf_hat = Array(TT)
uf_hat0 = Array(TT)
uf_hat1 = Array(TT)
w0 = Array(T)
u_hat, f_hat = uf_hat[:]

A = (2*np.pi)**3  # Equals inner(u, v)

# initialize (f initialized to zero, so all set)
X = T.local_mesh(True)
u[:] = ul(*X)
u_hat = T.forward(u, u_hat)

uh = TrialFunction(T)
vh = TestFunction(T)
k2 = -(inner(grad(vh), grad(uh)).diagonal_array / A + gamma)

def compute_rhs(duf_hat, uf_hat, up, T, Tp, w0):
    duf_hat.fill(0)
    u_hat, f_hat = uf_hat[:]
    du_hat, df_hat = duf_hat[:]
    df_hat[:] = k2*u_hat
    up = Tp.backward(u_hat, up)
    df_hat += Tp.forward(gamma*up**3, w0)
    du_hat[:] = f_hat
    return duf_hat

def energy_fourier(comm, N, a):
    result = 2*np.sum(abs(a[...,1:-1])**2) + np.sum(abs(a[...,0])**2) \
             + np.sum(abs(a[...,-1])**2)
    result =  comm.allreduce(result)
    return result

# Integrate using a 4th order Rung-Kutta method
a = [1./6., 1./3., 1./3., 1./6.]         # Runge-Kutta parameter
b = [0.5, 0.5, 1.]                       # Runge-Kutta parameter
t = 0.0
dt = 0.0025*4
end_time = 50.
tstep = 0
if rank == 0:
    plt.figure()
    im = plt.contourf(X[0][..., 0], X[1][..., 0], u[..., 4], 100)
    plt.draw()
    plt.pause(1e-4)
t0 = time()
K = np.array(T.local_wavenumbers(True, True))
while t < end_time-1e-8:
    t += dt
    tstep += 1
    uf_hat1[:] = uf_hat0[:] = uf_hat
    for rk in range(4):
        duf = compute_rhs(duf, uf_hat, up, T, Tp, w0)
        if rk < 3:
            uf_hat[:] = uf_hat0 + b[rk]*dt*duf
        uf_hat1 += a[rk]*dt*duf
    uf_hat[:] = uf_hat1

    if tstep % 50 == 0:
        uf = TT.backward(uf_hat, uf)
        ekin = 0.5*energy_fourier(T.comm, np.array(N), f_hat)
        es = 0.5*energy_fourier(T.comm, np.array(N), 1j*K*u_hat)
        eg = gamma*np.sum(0.5*u**2 - 0.25*u**4)/np.prod(np.array(N))
        eg =  comm.allreduce(eg)
        if rank == 0:
            im.ax.clear()
            im.ax.contourf(X[0][..., 0], X[1][..., 0], u[..., 4], 100)
            plt.pause(1e-6)
            print("Time = %2.2f Total energy = %2.8e" %(t, ekin+es+eg))
        comm.barrier()

print("Time ", time()-t0)
!ec

======= Bibliography =======

## Publish (https://bitbucket.org/logg/publish is used to
## handle references. The line below specifies the name of
## the Publish database file (see the doconce manual for details).

BIBFILE: papers.pub
